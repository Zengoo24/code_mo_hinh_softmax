import cv2
import mediapipe as mp
import numpy as np
import joblib
import os
import sys
import time
from ultralytics import YOLO

# ======================================================================
# 1. C·∫§U H√åNH V√Ä T·∫¢I MODEL
# ======================================================================

# üõë C·∫§U H√åNH ƒê∆Ø·ªúNG D·∫™N C·ª¶A B·∫†N üõë
# Vui l√≤ng thay ƒë·ªïi c√°c ƒë∆∞·ªùng d·∫´n n√†y cho ph√π h·ª£p v·ªõi m√°y t√≠nh c·ªßa b·∫°n
YOLO_MODEL_PATH = r"E:\PythonProject\data\New folder\best (1).pt"
MY_IMAGE_PATH = r"E:\PythonProject\data\New folder\off-wheel\2274.jpg" # ‚ö†Ô∏è THAY ƒê·ªîI ƒê∆Ø·ªúNG D·∫™N N√ÄY
# ----------------------------------

try:
    # T·∫£i c√°c model c·∫ßn thi·∫øt (Y√äU C·∫¶U PH·∫¢I HU·∫§N LUY·ªÜN L·∫†I V·ªöI 128 ƒê·∫∂C TR∆ØNG M·ªöI)
    model_data = joblib.load("softmax_wheel_model.pkl")
    scaler = joblib.load("scaler_wheel.pkl")
    YOLO_MODEL = YOLO(YOLO_MODEL_PATH)

except FileNotFoundError as e:
    print(f"‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y file c·∫ßn thi·∫øt: {e.filename}. H√£y ki·ªÉm tra l·∫°i.")
    sys.exit()
except Exception as e:
    print(f"‚ùå L·ªói t·∫£i m√¥ h√¨nh YOLO ho·∫∑c Joblib: {e}")
    sys.exit()

W = model_data["W"]
b = model_data["b"]
CLASS_NAMES = model_data["classes"]
X_mean = scaler["X_mean"]
X_std = scaler["X_std"]

# C√ÅC H·∫∞NG S·ªê V√Ä KHAI B√ÅO MP
mp_hands = mp.solutions.hands
mp_drawing = mp.solutions.drawing_utils
EPS = 1e-8
# ƒê√É ƒê·∫∂T EXPECTED_FEATURES = 128 (ph·∫£i kh·ªõp v·ªõi logic tr√≠ch xu·∫•t m·ªõi)
EXPECTED_FEATURES = 128
if W.shape[0] != EXPECTED_FEATURES:
    print(f"‚ùå L·ªñI: M√¥ h√¨nh Softmax c·∫ßn {EXPECTED_FEATURES} ƒë·∫∑c tr∆∞ng nh∆∞ng file .pkl ch·ªâ c√≥ {W.shape[0]}.")
    print("Vui l√≤ng HU·∫§N LUY·ªÜN L·∫†I m√¥ h√¨nh Softmax b·∫±ng d·ªØ li·ªáu 128 chi·ªÅu m·ªõi.")
    sys.exit()


# ======================================================================
# 2. H√ÄM C·ªêT L√ïI (SOFTMAX, YOLO, V√Ä TR√çCH XU·∫§T ƒê·∫∂C TR∆ØNG 128 CHI·ªÄU)
# ======================================================================

def softmax(z):
    """T√≠nh to√°n h√†m Softmax."""
    z -= np.max(z, axis=1, keepdims=True)
    exp_z = np.exp(z)
    return exp_z / np.sum(exp_z, axis=1, keepdims=True)


def detect_wheel_yolo(frame, yolo_model):
    """Ph√°t hi·ªán v√¥ lƒÉng b·∫±ng YOLOv8 v√† tr·∫£ v·ªÅ (bbox, x, y, r)."""
    results = yolo_model(frame, verbose=False, conf=0.5, classes=[0])

    for result in results:
        boxes = result.boxes
        if len(boxes) > 0:
            box = boxes[0].xyxy[0].cpu().numpy().astype(int)
            x_min, y_min, x_max, y_max = box

            x_w = (x_min + x_max) // 2
            y_w = (y_min + y_max) // 2
            r_w = int((x_max - x_min + y_max - y_min) / 4)

            return (x_min, y_min, x_max, y_max), (x_w, y_w, r_w)

    return None, None


def extract_features(image, wheel_coords):
    """
    Tr√≠ch xu·∫•t 128 ƒë·∫∑c tr∆∞ng tay, bao g·ªìm t·ªça ƒë·ªô, kho·∫£ng c√°ch t∆∞∆°ng ƒë·ªëi v√† g√≥c ƒë·ªô.
    Logic n√†y ph·∫£i kh·ªõp ho√†n to√†n v·ªõi script t·∫°o d·ªØ li·ªáu NPZ.
    """
    xw, yw, rw = wheel_coords
    h, w, _ = image.shape
    feats_all = []

    with mp_hands.Hands(static_image_mode=True, max_num_hands=2) as hands:
        rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        res = hands.process(rgb)

        if not res.multi_hand_landmarks:
            return None

        for hand_landmarks in res.multi_hand_landmarks:
            feats = []
            normalized_coords = []

            # 1. Tr√≠ch xu·∫•t T·ªça ƒë·ªô chu·∫©n h√≥a (63 ƒë·∫∑c tr∆∞ng: 21 * x,y,z)
            for lm in hand_landmarks.landmark:
                feats.extend([lm.x, lm.y, lm.z])
                normalized_coords.append(np.array([lm.x, lm.y]))

                # 2. ƒê·∫∑c tr∆∞ng Kho·∫£ng c√°ch ƒë·∫øn t√¢m v√¥ lƒÉng (1 ƒë·∫∑c tr∆∞ng)
            hx = hand_landmarks.landmark[0].x * w
            hy = hand_landmarks.landmark[0].y * h
            dist_to_center = np.sqrt((xw - hx) ** 2 + (yw - hy) ** 2)
            feats.append(dist_to_center / (rw + EPS))

            # --- TH√äM C√ÅC ƒê·∫∂C TR∆ØNG M·ªöI (D·∫•u hi·ªáu c·ªßa vi·ªác N·∫Øm) ---

            # a) ƒê·∫∑c tr∆∞ng v·ªã tr√≠ t∆∞∆°ng ƒë·ªëi c·ªßa c√°c ƒë·∫ßu ng√≥n tay so v·ªõi t√¢m v√¥ lƒÉng (10 ƒë·∫∑c tr∆∞ng)
            tip_indices = [4, 8, 12, 16, 20]

            for i in tip_indices:
                lm_tip = hand_landmarks.landmark[i]

                tip_x = lm_tip.x * w
                tip_y = lm_tip.y * h

                # Kho·∫£ng c√°ch t∆∞∆°ng ƒë·ªëi
                rel_dist = np.sqrt((xw - tip_x) ** 2 + (yw - tip_y) ** 2)
                feats.append(rel_dist / (rw + EPS))

                # G√≥c t∆∞∆°ng ƒë·ªëi
                angle = np.arctan2(tip_y - yw, tip_x - xw) / np.pi
                feats.append(angle)

            # b) ƒê·∫∑c tr∆∞ng Kho·∫£ng c√°ch gi·ªØa c√°c ng√≥n tay (10 ƒë·∫∑c tr∆∞ng)
            pairs = [(5, 8), (9, 12), (13, 16), (17, 20), (0, 5)]
            for i, j in pairs:
                p_i = normalized_coords[i]
                p_j = normalized_coords[j]

                distance = np.linalg.norm(p_i - p_j)
                feats.append(distance)

            feats_all.extend(feats)

        # C·∫Øt ho·∫∑c th√™m 0.0 ƒë·ªÉ ƒë·∫£m b·∫£o ƒë√∫ng EXPECTED_FEATURES (128)
        if len(feats_all) < EXPECTED_FEATURES:
            feats_all.extend([0.0] * (EXPECTED_FEATURES - len(feats_all)))

        feats_all = feats_all[:EXPECTED_FEATURES]

    return np.array(feats_all, dtype=np.float32)


# ======================================================================
# 3. H√ÄM D·ª∞ ƒêO√ÅN V√Ä HI·ªÇN TH·ªä CH√çNH
# ======================================================================
def predict_image_and_show(image_path):
    img = cv2.imread(image_path)
    if img is None:
        print(f"‚ùå Kh√¥ng th·ªÉ ƒë·ªçc ·∫£nh t·∫°i: {image_path}")
        return

    print(f"\n·∫¢nh ƒëang ki·ªÉm tra: {os.path.basename(image_path)}")

    # 1. PH√ÅT HI·ªÜN V√î LƒÇNG B·∫∞NG YOLO
    bbox, wheel_coords = detect_wheel_yolo(img, YOLO_MODEL)

    if wheel_coords is None:
        cv2.putText(img, "WHEEL NOT FOUND", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3, cv2.LINE_AA)
        print("‚ö†Ô∏è B·ªè qua: YOLO kh√¥ng ph√°t hi·ªán ƒë∆∞·ª£c v√¥-lƒÉng.")
        cv2.imshow("YOLOv8 Test", img);
        cv2.waitKey(0);
        cv2.destroyAllWindows()
        return

    # 2. TR√çCH XU·∫§T ƒê·∫∂C TR∆ØNG (S·ª≠ d·ª•ng 128 ƒë·∫∑c tr∆∞ng m·ªõi)
    features = extract_features(img, wheel_coords)

    # üõë LU·∫¨T C·ª®NG (KH√îNG TAY) -> R·ªúI üõë
    if features is None:
        final_predicted_class = "off-wheel"
        display_label = "ROI (OFF-WHEEL)"
        final_color = (0, 0, 255)  # ƒê·ªè/Blue cho OFF

    else:
        # 3. D·ª∞ ƒêO√ÅN SOFTMAX
        X_sample = features.reshape(1, -1)
        X_scaled = (X_sample - X_mean) / X_std
        z = X_scaled @ W + b
        probabilities = softmax(z)[0]
        predicted_index = np.argmax(probabilities)
        final_predicted_class = CLASS_NAMES[predicted_index]

        # 4. G√°n nh√£n hi·ªÉn th·ªã
        display_label = f"{final_predicted_class.upper()} ({probabilities[predicted_index] * 100:.2f}%)"
        final_color = (0, 255, 0) if final_predicted_class == "on-wheel" else (0, 0, 255)  # Xanh l√° cho ON, ƒê·ªè cho OFF

    print(f"-> K·∫æT QU·∫¢ CU·ªêI: {display_label}")

    # 5. HI·ªÇN TH·ªä K·∫æT QU·∫¢ TR·ª∞C QUAN

    # V·∫Ω V√¥ lƒÉng
    x_min, y_min, x_max, y_max = bbox
    xw, yw, rw = wheel_coords

    cv2.rectangle(img, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)  # Bounding Box YOLO
    cv2.circle(img, (xw, yw), rw, (255, 0, 255), 2)  # V√≤ng tr√≤n ∆∞·ªõc t√≠nh (Magenta)
    cv2.circle(img, (xw, yw), 5, (0, 0, 255), -1)  # T√¢m (ƒê·ªè)

    # V·∫Ω Tay (landmarks)
    with mp_hands.Hands(static_image_mode=True, max_num_hands=2) as hands:
        rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        res = hands.process(rgb)
        if res.multi_hand_landmarks:
            for hand_landmarks in res.multi_hand_landmarks:
                # ƒê·ªïi m√†u v·∫Ω tay th√†nh m√†u Xanh l∆° (Cyan) nh∆∞ trong ·∫£nh g·ªëc ƒë·ªÉ d·ªÖ nh√¨n
                mp_drawing.draw_landmarks(img, hand_landmarks, mp_hands.HAND_CONNECTIONS,
                                          mp_drawing.DrawingSpec(color=(255, 255, 0), thickness=2, circle_radius=2),
                                          mp_drawing.DrawingSpec(color=(255, 200, 0), thickness=2, circle_radius=2))

    # üõë HI·ªÇN TH·ªä K·∫æT QU·∫¢ PH√ÇN LO·∫†I CU·ªêI üõë
    cv2.putText(img, display_label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1.2, final_color, 3, cv2.LINE_AA)

    cv2.imshow("Wheel Prediction", img)
    cv2.waitKey(0)
    cv2.destroyAllWindows()


# ======================================================================
# 4. TH·ª∞C THI CH√çNH
# ======================================================================
if __name__ == "__main__":
    predict_image_and_show(MY_IMAGE_PATH)
